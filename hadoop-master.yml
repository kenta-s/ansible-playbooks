---
- name: install Hadoop
  hosts: hadoop-master
  become: yes
  become_user: root

  tasks:
    - name: epel-release
      yum:
        name: epel-release
        state: latest
    - name: Install python-pip
      yum:
        name: python-pip
        state: latest
    - name: Install pexpect
      command: 'pip install pexpect'
    - name: download JDK8
      get_url:
        url: http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm
        dest: /tmp/jdk-8u131-linux-x64.rpm
        mode: 0644
        validate_certs: no
        headers: "Cookie: oraclelicense=accept-securebackup-cookie"
    - name: be sure JDK8 is installed
      yum:
        name: /tmp/jdk-8u131-linux-x64.rpm
        state: present      

    - name: CDH5
      get_url:
        url: https://archive.cloudera.com/cdh5/redhat/7/x86_64/cdh/cloudera-cdh5.repo
        dest: /etc/yum.repos.d/cloudera-cdh5.repo
    - name: RPM key
      rpm_key:
        state: present
        key: https://archive.cloudera.com/cdh5/redhat/7/x86_64/cdh/RPM-GPG-KEY-cloudera
    - name: yum clean
      shell: yum clean all
    - name: Resource Manager host
      yum:
        name: hadoop-yarn-resourcemanager
        state: latest
    - name: NameNode host
      yum:
        name: hadoop-hdfs-namenode
        state: latest
    - name: MR history server
      yum:
        name: hadoop-mapreduce-historyserver
        state: latest
    - name: YARN proxy server
      yum:
        name: hadoop-yarn-proxyserver
        state: latest
    - name: copy hadoop conf dir
      command: 'sudo cp -r /etc/hadoop/conf.empty /etc/hadoop/conf.cluster'
    - name: add property to core-site.xml
      lineinfile:
        dest: /etc/hadoop/conf/core-site.xml
        insertafter: '<configuration>'
        line: '{{ item }}'
        state: present
        backup: yes
      with_items:
        - "<property>\n<name>fs.defaultFS</name>\n<value>hdfs://master:8020</value>\n</property>"
    - name: add property to hdfs-site.xml
      lineinfile:
        dest: /etc/hadoop/conf/hdfs-site.xml
        insertafter: '<configuration>'
        line: '{{ item }}'
        state: present
        backup: yes
      with_items:
        - "<property>\n<name>dfs.permissions.superusergroup</name>\n<value>hadoop</value>\n</property>\n<property>\n<name>dfs.datanode.name.dir</name>\n<value>/var/lib/hadoop-hdfs/cache/dfs/data</value>\n</property>"
    - name: prepare cache dir 1
      command: 'sudo mkdir -p /var/lib/hadoop-hdfs/cache/dfs/name'
    - name: prepare cache dir 2
      command: 'sudo mkdir -p /var/lib/hadoop-hdfs/cache/dfs/data'
    - name: chown cache dir
      command: 'sudo chown hdfs:hadoop -R /var/lib/hadoop-hdfs/cache/dfs'
    - name: format namenode
      expect:
        command: 'sudo -u hdfs hdfs namenode -format'
        responses:
          'Re-format filesystem in Storage Directory': 'Y'
    - name: start namenode
      service:
        name: hadoop-hdfs-namenode
        state: started
